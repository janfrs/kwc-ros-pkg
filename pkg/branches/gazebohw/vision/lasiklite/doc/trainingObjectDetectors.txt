******************************************************************************
HOW TO TRAIN A SLIDING-WINDOW OBJECT DETECTOR
by Stephen Gould <sgould@stanford.edu>
******************************************************************************

This article describes how to train and test a 2-d sliding-window
object detector using the STAIR Vision Library (Lasik). Sliding-window
object detection is a popular technique for identifying and localizing
objects in an image. Here a window (of fixed aspect ratio) is scanned
across the image. At each location and scale, features are extracted
from within the window and applied to a classifier to give the
probability that the window (tightly) bounds the object for which the
classifier was trained. Contextual information is usually added to
improve performance of these detectors (although our standard
implementation does not do this). Our detectors are based on the
patch-based detectors introduced by Torralba (see references
below). The main problem with sliding-window detectors is that they
only work for objects with (fairly) fixed aspect ratios. They are also
sensitive to the object's orientation.

****************
Data Preparation
****************

You will need to prepare a dataset of positive and negative training examples (jpg images). Experience has shown that around 100-500 positive examples and 10000-20000 negative example results fairly decent performance.

 * The positive examples should contain cropped images that leave a
   small border around the edge so that the detector can take
   advantage of edge features. They should also contain a wide variety
   of instances from the object class in the same orientations in
   which you want them to be detected.

 * All positive examples should have approximately the same aspect
   ratio. However, you do not need to scale the images to the same
   size (the training code will do that automatically). If some
   objects in the class (or some orientations) exhibit a different
   aspect ratio then you can crop the images to be square with the
   object centered.

 * The negative example can be randomly snipped out of a training
   video. Be sure to collect examples at different scales. Note that
   by constructing a negative set this way there will be high
   correlation in these examples so you will need lots of them. The
   same negative set can be used for training multiple object classes.

********
Training
********

The script trainObjectDetector.pl implements the following pipeline
for training an object detector. You will need to change the location
it expects to find the data.

*****************************
Building the Patch Dictionary
*****************************

The first step to training the detector is to build a patch
dictionary. You need to decide on the base size for your
classifier. This is the smallest scale at which objects will be
detected. A typical size is 32-by-32 (if your object has a square
aspect ratio), but it can be larger for bigger objects. Small patches
(typically 10 per example) are randomly selected from the positive
training images to construct the initial dictionary. The dictionary
will eventually be trimmed to remove patches which don't contribute to
the classifier.

Example command-line:

  bin/buildPatchDictionary -n 10 -o models/dictionary.mug.txt ~/data/mugs 32 32


*******************************
Building a Patch Response Cache
*******************************

Although the object detectors can be trained directly from images, it
is best to first compute a cache of all the patch responses. This is
because the patch response calculations take a long time (especially
when the initial dictionary is large) and caching the responses allows
you to recover from crashes (or compute responses in parallel).

A response cache should be created separately for the positive and
negative training examples. Here is an example command-line:

  bin/buildPatchResponseCache -maxImages 1000 ~/data/mugs \
      /tmp/cache-mugs-pos models/dictionary.mug.txt
  bin/buildPatchResponseCache -maxImages 20000 ~/data/other \
      /tmp/cache-mugs-neg models/dictionary.mug.txt


******************************
Training the Boosted Detectors
******************************

Once the patch response cache is built, the boosted detector can be
trained very quickly. For example:

  bin/trainObjectClassifier -cached -o models/model.mug \
      -p models/dictionary.mug.txt \
      /tmp/cache-mugs-pos /tmp/cache-mugs-neg


*****************************
Trimming the Patch Dictionary
*****************************

Computing patch responses is expensive so the final stage in training
is to remove the patches which are not actually used by the
detector. The Perl script trimDictionary.pl will remove unused patches
from the dictionary and renumber the features indexes in the learned
model file accordingly.

Example command-line:

  scripts/trimDictionary.pl models/dictionary.mug.txt models/mug.model


******************
Improving Training
******************

One way to improve training is to perform the above procedure on a
smaller negative training set, and then re-run with a much larger set
using the trimmed dictionary. Make sure you clean the cache between
training runs since the dictionary will have changed.

*******
Testing
*******

TO DO


**********
References
**********

 * A. Torralba, K. Murphy, and W. Freeman. Contextual models for object per frame per object class). Performance can be improved by etection using boosted random fields. In NIPS, 2004.
 * A. Torralba, K.P. Murphy, and W.T. Freeman. Sharing visual features pruning parts of the scene based on 3-d cues for multiclass and multiview object detection. PAMI, 2007.
 * P. Viola and M.J. Jones. Robust real-time object detection. IJCV, 2001.
 * P. Viola and M.J. Jones. Robust real-time face detection. IJCV, 2004. 
